{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aaf282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "## image, label 설정\n",
    "img_path = 'C:/cube_resized/1300/'\n",
    "lbl_path = 'C:/merged_label/1300/'\n",
    "\n",
    "str_path = next(os.walk(img_path))[1]\n",
    "\n",
    "cnt = 0\n",
    "files = []\n",
    "for i in str_path:\n",
    "    for j in next(os.walk(lbl_path + i))[2]:\n",
    "        files.append(i + '/' + j[-8:])\n",
    "        cnt += 1\n",
    "\n",
    "low_image = np.zeros((cnt,256,256,3))\n",
    "low_label = np.zeros((cnt,256,256))\n",
    "\n",
    "for n, strength in enumerate(str_path):\n",
    "    image_paths = img_path + strength + '/'\n",
    "    label_paths = lbl_path + strength + '/'\n",
    "    ep = len(next(os.walk(label_paths))[2])\n",
    "    for i, lbl in enumerate(next(os.walk(label_paths))[2]):\n",
    "        \n",
    "        img = lbl[-8:]\n",
    "        \n",
    "        image = plt.imread(image_paths + img)\n",
    "        low_image[n*ep + i] = image[:,:,:3]\n",
    "        \n",
    "        label = plt.imread(label_paths + lbl)\n",
    "        if label.ndim == 3:\n",
    "            low_label[n*ep + i] = label[:,:,:1].reshape(256,256)\n",
    "        else:\n",
    "            low_label[n*ep + i] = label\n",
    "            \n",
    "            \n",
    "# ## 시각화\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.subplot(2,2,1)\n",
    "# plt.imshow(low_image[5])\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.imshow(low_label[5])\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.imshow(low_image[15])\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.imshow(low_label[15])\n",
    "\n",
    "\n",
    "# Kfold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "df = pd.DataFrame({'file_name':files,'fold':[-1 for i in range(len(low_image))]})\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=32)\n",
    "\n",
    "for idx, (t,v) in enumerate(kf.split(low_image)):\n",
    "    df.loc[v, 'fold'] = idx\n",
    "\n",
    "\n",
    "# Augmentation\n",
    "import albumentations as A\n",
    "\n",
    "class Augmentation:\n",
    "    def __init__(self, size, mode='train'):\n",
    "        if mode == 'train':\n",
    "            self.transform = A.Compose([\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.ShiftScaleRotate(\n",
    "                    p=0.5,\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=45,\n",
    "                ),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.RandomBrightnessContrast(p=0.2),\n",
    "            ])\n",
    "    def __call__(self, **kwargs):\n",
    "        if self.transform:\n",
    "            augmented = self.transform(**kwargs)\n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            return img, mask\n",
    "        \n",
    "        \n",
    "# Generator\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, df, image, label,\n",
    "                fold, image_size, mode='train', shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        # train : 해당 fold에 해당하는 데이터를 제외하고 가져옴\n",
    "        # val : 해당 fold에 해당하는 데이터를 가져옴\n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "        \n",
    "        \n",
    "        # Data Augmentation\n",
    "        self.transform = Augmentation(image_size, mode)\n",
    "        \n",
    "        # 학습을 시작할 때도(첫 epoch) 셔플해주려면,\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.df) / self.batch_size)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        strt = idx * self.batch_size\n",
    "        fin = (idx + 1) * self.batch_size\n",
    "        data = self.df.iloc[strt:fin]\n",
    "        \n",
    "        batch_x, batch_y = self.image, self.label\n",
    "        \n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "        \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    batch_size=8,\n",
    "    df=df,\n",
    "    image=low_image,\n",
    "    label=low_label,\n",
    "    fold=1,\n",
    "    image_size=256,\n",
    "    mode='train',\n",
    "    shuffle=True)\n",
    "\n",
    "valid_generator = DataGenerator(\n",
    "    batch_size=8,\n",
    "    df=df,\n",
    "    image=low_image,\n",
    "    label=low_label,\n",
    "    fold=1,\n",
    "    image_size=256,\n",
    "    mode='val',\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "# Loss\n",
    "import tensorflow.keras.losses as losses\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    \n",
    "    smooth = 1.  # 0으로 나누는 것 방지\n",
    "    \n",
    "    # Flatten\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    \n",
    "    score = intersection / (union + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    smooth = 1.  # 0으로 나누는 것 방지\n",
    "    \n",
    "    # Flatten\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    \n",
    "    score = (2 * intersection) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \n",
    "    loss = 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    \n",
    "    loss = 1. * losses.binary_crossentropy(y_true,y_pred) + 1. * dice_loss(y_true, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def Predict_model(images):\n",
    "    \n",
    "    image_datas = np.zeros((len(images), 256,256,3))\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        image_datas[i] = images[i][:,:,:3]\n",
    "        \n",
    "    preds = model.predict(image_datas)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        preds[i] = preds[i]\n",
    "        \n",
    "    return preds\n",
    "\n",
    "\n",
    "# model compile\n",
    "from keras_unet.models import custom_unet\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "result = []\n",
    "\n",
    "\n",
    "model = custom_unet(\n",
    "    input_shape=(256, 256, 3),\n",
    "    use_batch_norm=True,  # True로 해주는게 좋음\n",
    "    upsample_mode='deconv',  # deconv가 일반적\n",
    "    use_attention=True,  # hyperparameter로 비교하지만, 사용하는게 좋음\n",
    "    filters=17,\n",
    "    num_layers=3 ,  # conv layer갯수로 얼마나 깊은지 hyperparameter\n",
    "    num_classes=4,\n",
    "    dropout_type='spatial',  # hyperparameter의 의미로 'standard'와 비교해서 쓰지만, 일반적으로 spatial로 하는게 성능이 좋다고 알려짐\n",
    "    dropout=0.5,\n",
    "    output_activation='sigmoid')\n",
    "\n",
    "model.compile(optimizer='adam', loss=bce_dice_loss, metrics=['accuracy', iou])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_accracy', min_delta = 0, patience = 20, mode = 'auto')\n",
    "\n",
    "# 학습\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=1000,\n",
    "    verbose=1,\n",
    "    callbacks = [early_stopping])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## image, label 설정\n",
    "test_img_path_24 = 'C:/cube_resized/1300/24/'\n",
    "\n",
    "num_24 = len(next(os.walk(test_img_path_24))[2])\n",
    "\n",
    "test_images_24 = np.zeros((num_24,256,256,3))\n",
    "\n",
    "for i in range(num_24):\n",
    "    test_images_24[i] = plt.imread(test_img_path_24 + next(os.walk(test_img_path_24))[2][i])[:,:,:3]\n",
    "    \n",
    "    \n",
    "test_labels_24 = Predict_model(test_images_24)\n",
    "\n",
    "\n",
    "\n",
    "porosity_24 = []\n",
    "for i in range(test_labels_24.shape[0]):\n",
    "    cnt = 0\n",
    "    for j in range(256):\n",
    "        for k in range(256):\n",
    "            cnt += test_labels_24[i][j][k]\n",
    "                \n",
    "    porosity_24.append(cnt/(256*256)*100)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## image, label 설정\n",
    "test_img_path_35 = 'C:/cube_resized/1300/35/'\n",
    "\n",
    "num_35 = len(next(os.walk(test_img_path_35))[2])\n",
    "\n",
    "test_images_35 = np.zeros((num_35,256,256,3))\n",
    "\n",
    "for i in range(num_35):\n",
    "    test_images_35[i] = plt.imread(test_img_path_35 + next(os.walk(test_img_path_35))[2][i])[:,:,:3]\n",
    "    \n",
    "    \n",
    "test_labels_35 = Predict_model(test_images_35)\n",
    "\n",
    "\n",
    "\n",
    "porosity_35 = []\n",
    "for i in range(test_labels_35.shape[0]):\n",
    "    cnt = 0\n",
    "    for j in range(256):\n",
    "        for k in range(256):\n",
    "            cnt += test_labels_35[i][j][k]\n",
    "                \n",
    "    porosity_35.append(cnt/(256*256)*100)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "## image, label 설정\n",
    "test_img_path_50 = 'C:/cube_resized/1300/50/'\n",
    "\n",
    "num_50 = len(next(os.walk(test_img_path_50))[2])\n",
    "\n",
    "test_images_50 = np.zeros((num_50,256,256,3))\n",
    "\n",
    "for i in range(num_50):\n",
    "    test_images_50[i] = plt.imread(test_img_path_50 + next(os.walk(test_img_path_50))[2][i])[:,:,:3]\n",
    "    \n",
    "    \n",
    "test_labels_50 = Predict_model(test_images_50)\n",
    "\n",
    "\n",
    "\n",
    "porosity_50 = []\n",
    "for i in range(test_labels_50.shape[0]):\n",
    "    cnt = 0\n",
    "    for j in range(256):\n",
    "        for k in range(256):\n",
    "            cnt += test_labels_50[i][j][k]\n",
    "                \n",
    "    porosity_50.append(cnt/(256*256)*100)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(porosity_24)):\n",
    "    porosity_24[i] = porosity_24[i][0]\n",
    "    \n",
    "for i in range(len(porosity_35)):\n",
    "    porosity_35[i] = porosity_35[i][0]\n",
    "    \n",
    "for i in range(len(porosity_50)):\n",
    "    porosity_50[i] = porosity_50[i][0]\n",
    "\n",
    "\n",
    "\n",
    "avg_pore_24 = np.average(porosity_24)\n",
    "avg_pore_35 = np.average(porosity_35)\n",
    "avg_pore_50 = np.average(porosity_50)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('multi_first.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d805b1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0001.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'sp0001.png'\n",
    "\n",
    "a[-8:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaff9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
